{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch_geometric as torch_g\n",
    "\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import ase.io\n",
    "import ase\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/share/DATA/NeuralOpt/Interpolations/Geodesic_interp\")\n",
    "from get_geodesic_energy import ATOMIC_RADIUS, morse_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug] (GrambowDataModule) \n",
      "\tbase_path: /home/ksh/MolDiff/NeuralOpt/neural_opt\n",
      "\troot_path: /home/ksh/MolDiff/NeuralOpt/neural_opt/data\n",
      "DataBatch(x=[29], edge_index=[2, 196], pos_1=[29, 3], pos_2=[29, 3], batch=[29], ptr=[3])\n"
     ]
    }
   ],
   "source": [
    "from torch_data_test.proc import *\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(\"torch_data_test/config.yaml\")\n",
    "datamodule = GrambowDataModule(config)\n",
    "\n",
    "loader = datamodule.train_dataloader()\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrapper class to save atoms object\n",
    "\n",
    "class Wrapper:\n",
    "    def __init__(self, atoms_0, atoms_T, q_type=\"DM\", alpha=1.7, beta=0.01, gamma=0.01, using_jacobian=True, svd_tol=1e-4):\n",
    "        self.atoms_0 = atoms_0\n",
    "        self.atoms_T = atoms_T\n",
    "        # assert q_type in [\"DM\", \"morse\"]\n",
    "        self.q_type = q_type\n",
    "        self.svd_tol = svd_tol\n",
    "        self.re = torch.Tensor(self.get_re(atoms_T))\n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        self.gamma = gamma\n",
    "        self.morse_scaler = morse_scaler(self.re, self.alpha, self.beta)\n",
    "        self.scaler_factor = 1.0\n",
    "        self.using_jacobian = using_jacobian\n",
    "        return\n",
    "\n",
    "    def get_re(self, atoms, threshold=np.inf):\n",
    "        from scipy.spatial import KDTree\n",
    "\n",
    "        rijset = set()\n",
    "        tree = KDTree(atoms.positions)\n",
    "        pairs = tree.query_pairs(threshold)\n",
    "        rijset.update(pairs)\n",
    "        rijlist = sorted(rijset)\n",
    "\n",
    "        radius = np.array([ATOMIC_RADIUS.get(atom.capitalize(), 1.5) for atom in atoms.get_chemical_symbols()])\n",
    "        re = np.array([radius[i] + radius[j] for i, j in rijlist])\n",
    "        return re\n",
    "\n",
    "    def calc_inverse_jacobian(self, pos, q_type):\n",
    "        edge_index, edg_length = self.pos_to_dist(pos)\n",
    "        distance = pdist(pos)\n",
    "        distance_e = self.get_re(self.atoms_T)\n",
    "        inverse_jacobain = []\n",
    "\n",
    "        for ij, d, de in zip(edge_index.T, distance, distance_e):\n",
    "            jacob = torch.zeros(size=pos.size())\n",
    "            i, j = ij\n",
    "            pos_i, pos_j = pos[i], pos[j]\n",
    "            d_pos = pos_i - pos_j\n",
    "            if q_type == \"DM\":\n",
    "                dr_dd = d / d_pos\n",
    "                jacob[i] = dr_dd\n",
    "                jacob[j] = - dr_dd\n",
    "                \n",
    "            elif q_type == \"morse\":\n",
    "                dr_dq = d ** 3 * de  / - (self.alpha * np.exp(- self.alpha * (d / de - 1)) + self.beta * de ** 2) / d_pos\n",
    "                jacob[i] = dr_dq\n",
    "                jacob[j] = - dr_dq\n",
    "            inverse_jacobain.append(jacob.flatten())\n",
    "        return torch.stack(inverse_jacobain, dim=0)\n",
    "                \n",
    "        \n",
    "    def calc_jacobian(self, pos, q_type):\n",
    "        debug = False\n",
    "        # pos = Tensor, (N, 3)\n",
    "        edge_index, edge_length = self.pos_to_dist(pos)\n",
    "        distance = pdist(pos)\n",
    "        distance_e = self.get_re(self.atoms_T)\n",
    "\n",
    "        jacobian = []\n",
    "        for i_idx in range(len(pos)):\n",
    "            j_idx = list(range(len(pos)))\n",
    "            j_idx.remove(i_idx)\n",
    "            j_idx = torch.LongTensor(j_idx)\n",
    "\n",
    "            j_mask = torch.any(edge_index == i_idx, axis=0)\n",
    "            dd_dx = torch.zeros(size=(len(edge_length), 3))\n",
    "            dq_dx = torch.zeros(size=(len(edge_length), 3))\n",
    "            pos_i = pos[i_idx].reshape(1, -1)\n",
    "            pos_j = pos[j_idx]\n",
    "            if debug:\n",
    "                print(f\"debug] (old) \\n\\ti_idx = {i_idx}\", end=\"\")\n",
    "                print(f\"\\n\\t j_idx = \\n\\t\\t{j_idx}\")\n",
    "                print(f\"\\n\\t maked j_idx = \\n\\t\\t{edge_index[:, j_mask]}\")\n",
    "            dist = distance[j_mask].reshape(-1, 1)\n",
    "            dd_dx[j_mask] += (pos_i - pos_j) / dist\n",
    "\n",
    "            if q_type == \"DM\":\n",
    "                jacobian.append(dd_dx.T)\n",
    "\n",
    "            elif q_type == \"morse\":\n",
    "                dq_dd = - (self.alpha / distance_e[j_mask]) * np.exp(-self.alpha * (distance[j_mask] - distance_e[j_mask]) / distance_e[j_mask])\n",
    "                dq_dd -= self.beta * distance_e[j_mask] / (distance[j_mask] ** 2)\n",
    "                if debug:\n",
    "                    print(f\"debug] (old) dq_dd = {dq_dd}\")\n",
    "                dq_dx[j_mask] += dd_dx[j_mask] * dq_dd.reshape(-1, 1)\n",
    "                jacobian.append(dq_dx.T)\n",
    "                \n",
    "            elif q_type == \"morese+DM\":\n",
    "                raise NotImplementedError\n",
    "\n",
    "        return torch.cat(jacobian, dim=0)\n",
    "    \n",
    "    def calc_distance_hessian(self, pos, edge_index, distance):\n",
    "        N = len(pos)\n",
    "        K = len(edge_index)\n",
    "        hessian = torch.zeros(size=(K, 3 * N, 3 * N))\n",
    "        for k, (ij, d_ij) in enumerate(zip(edge_index, distance)):\n",
    "            i, j = ij\n",
    "            pos_i, pos_j = pos[i], pos[j]\n",
    "\n",
    "            # calculate hessian related to i, j atoms\n",
    "            d_pos = pos_i - pos_j\n",
    "            hess_ij = d_pos.reshape(1, -1) * d_pos.reshape(-1, 1)\n",
    "            hess_ij /= d_ij ** 3\n",
    "            hess_ij -= torch.eye(3) / d_ij\n",
    "            \n",
    "            # calculate hessian related to i, i atoms\n",
    "            hess_ii = d_pos.reshape(1, -1) * d_pos.reshape(-1, 1)\n",
    "            hess_ii /= - d_ij ** 3\n",
    "            hess_ii += torch.eye(3) / d_ij\n",
    "            \n",
    "            # hess_ii = hess_jj\n",
    "            hess_jj = hess_ii\n",
    "\n",
    "            hessian[k, 3 * i:3 * (i + 1), 3 * i:3 * (i + 1)] += hess_ii\n",
    "            hessian[k, 3 * j:3 * (j + 1), 3 * j:3 * (j + 1)] += hess_jj\n",
    "            hessian[k, 3 * i:3 * (i + 1), 3 * j:3 * (j + 1)] += hess_ij\n",
    "            hessian[k, 3 * j:3 * (j + 1), 3 * i:3 * (i + 1)] += hess_ij\n",
    "            \n",
    "        return hessian\n",
    "    \n",
    "    def calc_hessian(self, pos, q_type=None):\n",
    "        if q_type is None:\n",
    "            q_type = self.q_type\n",
    "            \n",
    "        edge_index, edge_length = self.pos_to_dist(pos)\n",
    "        edge_index = edge_index.T\n",
    "        distance = pdist(pos)\n",
    "        distance_e = self.get_re(self.atoms_T)\n",
    "\n",
    "        hessian = self.calc_distance_hessian(pos, edge_index, distance)\n",
    "        \n",
    "        if q_type == \"DM\":\n",
    "            return hessian\n",
    "        \n",
    "        elif q_type == \"morse\":\n",
    "            dq_dd = - self.alpha / distance_e * np.exp(-self.alpha * (distance - distance_e) / distance_e)\n",
    "            dq_dd -= self.beta * distance_e / (distance ** 2)\n",
    "            hessian_q = hessian * dq_dd.reshape(-1, 1, 1)\n",
    "            \n",
    "            for k, (ij, d_ij, de_ij) in enumerate(zip(edge_index, distance, distance_e)):\n",
    "                i, j = ij\n",
    "                pos_i, pos_j = pos[i], pos[j]\n",
    "                # calculate hessian related to i, j atoms\n",
    "                d_pos = pos_i - pos_j\n",
    "                hess_ij = d_pos.reshape(1, -1) * d_pos.reshape(-1, 1)\n",
    "                hess_ij /= - d_ij ** 2\n",
    "                coeff = self.alpha ** 2 / de_ij ** 2 * np.exp(-self.alpha * (d_ij - de_ij) / de_ij)  + 2 * self.beta * de_ij / (d_ij ** 3)\n",
    "                hess_ij *= coeff\n",
    "\n",
    "                # calculate hessian related to i, i atoms\n",
    "                hess_ii = - hess_ij\n",
    "                \n",
    "                hessian_q[k, 3 * i:3 * (i + 1), 3 * i:3 * (i + 1)] += hess_ii\n",
    "                hessian_q[k, 3 * j:3 * (j + 1), 3 * j:3 * (j + 1)] += hess_ii\n",
    "                hessian_q[k, 3 * i:3 * (i + 1), 3 * j:3 * (j + 1)] += hess_ij\n",
    "                hessian_q[k, 3 * j:3 * (j + 1), 3 * i:3 * (i + 1)] += hess_ij\n",
    "                \n",
    "            return hessian_q\n",
    "        \n",
    "        elif q_type == \"morese+DM\":\n",
    "            raise NotImplementedError\n",
    "        return \n",
    "             \n",
    "    def eq_transform(self, score_d, pos, edge_index, edge_length):\n",
    "        if self.using_jacobian:\n",
    "            jacobian = self.calc_jacobian(pos, q_type=self.q_type)\n",
    "            \n",
    "            score_pos = jacobian @ score_d.reshape(-1, 1)\n",
    "            return score_pos.reshape(-1, 3)\n",
    "            \n",
    "        if self.q_type == \"morse\":\n",
    "            edge_length = torch.Tensor(pdist(pos))\n",
    "            \n",
    "            N = pos.size(0)\n",
    "            dd_dr = - (self.alpha / self.re) * torch.exp(-self.alpha * (edge_length - self.re) / self.re) / edge_length\n",
    "            dd_dr -= self.beta * self.re / (edge_length ** 3)\n",
    "            dd_dr = dd_dr.reshape(-1, 1)\n",
    "            dd_dr = dd_dr * (pos[edge_index[0]] - pos[edge_index[1]])\n",
    "            score_d = score_d.reshape(-1, 1)\n",
    "            score_d *= self.scaler_factor\n",
    "            score_pos = scatter_add(dd_dr * score_d, edge_index[0], dim=0, dim_size=N)\n",
    "            score_pos += scatter_add(-dd_dr * score_d, edge_index[1], dim=0, dim_size=N)\n",
    "        \n",
    "        elif self.q_type == \"DM\":\n",
    "            N = pos.size(0)\n",
    "            dd_dr = (1.0 / edge_length).reshape(-1, 1) * (pos[edge_index[0]] - pos[edge_index[1]])\n",
    "            score_d = score_d.reshape(-1, 1)\n",
    "            score_pos = scatter_add(dd_dr * score_d, edge_index[0], dim=0, dim_size=N)\n",
    "            score_pos += scatter_add(-dd_dr * score_d, edge_index[1], dim=0, dim_size=N)\n",
    "        \n",
    "        elif self.q_type == \"morse+DM\":\n",
    "            edge_length = torch.Tensor(pdist(pos))\n",
    "            N = pos.size(0)\n",
    "            dd_dr = - (self.alpha / self.re) * torch.exp(-self.alpha * (edge_length - self.re) / self.re) / edge_length\n",
    "            dd_dr -= self.beta * self.re / (edge_length ** 3)\n",
    "            dd_dr += self.gamma / edge_length\n",
    "            dd_dr = dd_dr.reshape(-1, 1)\n",
    "            score_d *= self.scaler_factor\n",
    "            dd_dr = dd_dr * (pos[edge_index[0]] - pos[edge_index[1]])\n",
    "            score_d = score_d.reshape(-1, 1)\n",
    "            score_pos = scatter_add(dd_dr * score_d, edge_index[0], dim=0, dim_size=N)\n",
    "            score_pos += scatter_add(-dd_dr * score_d, edge_index[1], dim=0, dim_size=N)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return score_pos\n",
    "\n",
    "    def pos_to_dist(self, pos, q_type=None):\n",
    "        if q_type is None:\n",
    "            q_type = self.q_type\n",
    "        if q_type == \"morse\":\n",
    "            rij = pdist(pos)\n",
    "            wij = self.morse_scaler(rij)[0] * self.scaler_factor\n",
    "            # print(wij, type(wij))\n",
    "            # length = torch.Tensor(wij)\n",
    "            length = wij\n",
    "            index = torch.LongTensor(np.stack(np.triu_indices(len(pos), 1)))\n",
    "        elif q_type == \"DM\":\n",
    "            length = torch.Tensor(pdist(pos))\n",
    "            index = torch.LongTensor(np.stack(np.triu_indices(len(pos), 1)))\n",
    "        elif q_type == \"morse+DM\":\n",
    "            rij = pdist(pos)\n",
    "            wij = self.morse_scaler(rij)[0] * self.scaler_factor\n",
    "            wij += self.gamma * rij\n",
    "            length = torch.Tensor(wij)\n",
    "            index = torch.LongTensor(np.stack(np.triu_indices(len(pos), 1)))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return index, length\n",
    "\n",
    "    def reverse_diffusion_process(self, x_t, t, dt, params, x_0, x_T, coord=\"Cartesian\", h_coeff=0.0, verbose=True,\n",
    "                                  using_jacobian=True, sampling_test=1, inner_iteration=5):\n",
    "        beta_t = params.beta(t)\n",
    "\n",
    "        if coord == \"Cartesian\":\n",
    "            diff, coeff, v1, v2, v3, v4 = self.reverse_score(x_t, t, params, x_0, x_T, verbose=verbose)\n",
    "            reverse_score_ = diff * coeff\n",
    "            dw = torch.sqrt(beta_t * dt) * torch.randn_like(diff)\n",
    "            dx = - 1.0 * reverse_score_ * dt + dw\n",
    "        else:\n",
    "            diff, coeff, v1, v2, v3, v4 = self.reverse_score2(x_t, t, params, x_0, x_T, verbose=verbose)\n",
    "            index, d_t = self.pos_to_dist(x_t)\n",
    "\n",
    "            if sampling_test == 0:\n",
    "                # every displacement is first calculated on the q-space, and then transformed to the Cartesian space\n",
    "                reverse_score_ = diff * coeff\n",
    "                dw = torch.sqrt(beta_t * dt) * torch.randn_like(diff)\n",
    "                dd = - 1.0 * reverse_score_ * dt + dw\n",
    "\n",
    "                dx = self.eq_transform(dd, x_t, index, d_t)\n",
    "            \n",
    "            elif sampling_test == 1:\n",
    "                reverse_score_ = diff * coeff\n",
    "                dw = torch.sqrt(beta_t * dt) * torch.randn_like(diff)\n",
    "                dd = - 1.0 * reverse_score_ * dt + dw   \n",
    "                x_tm1 = self.exponential_ode_solver(x_t, -dd, q_type=self.q_type, num_iter=inner_iteration, check_dot_every=3)\n",
    "                dx = - x_tm1 + x_t\n",
    "                \n",
    "        x_tm1 = x_t - dx\n",
    "        return x_tm1, v1, v2, v3, v4\n",
    "\n",
    "    def reverse_ode_process(self, x_t, t, dt, params, x_0, x_T, coord=\"Cartesian\", h_coeff=0.0, verbose=True,\n",
    "                            using_jacobian=True, sampling_test=1, inner_iteration=5):\n",
    "        beta_t = params.beta(t)\n",
    "\n",
    "        if coord == \"Cartesian\":\n",
    "            diff, coeff, v1, v2, v3, v4 = self.reverse_score(x_t, t, params, x_0, x_T, verbose=verbose)\n",
    "            reverse_score_ = diff * coeff\n",
    "            dx = - 0.5 * reverse_score_ * dt\n",
    "            print(f\"Debug ({t:0.3f}): \\n\\t1) diff norm and dx norm {diff.norm():0.4f}, {dx.norm():0.6f}\")\n",
    "        else:\n",
    "            diff, coeff, v1, v2, v3, v4 = self.reverse_score2(x_t, t, params, x_0, x_T, verbose=verbose)\n",
    "            index ,d_t = self.pos_to_dist(x_t)\n",
    "\n",
    "            if sampling_test == 0:\n",
    "                reverse_score_ = diff * coeff\n",
    "                dd = - 0.5 * reverse_score_ * dt\n",
    "                dx = self.eq_transform(dd, x_t, index, d_t)                \n",
    "                # Want to check why eq-transform does not work well\n",
    "                diff_d = diff\n",
    "                diff_x = self.eq_transform(diff_d, x_t, index, d_t)\n",
    "                print(f\"Debug ({t:0.3f}): \\n\\t1) diff-d norm and diff-x norm {diff_d.norm():0.4f}, {diff_x.norm():0.4f} \\n\\t2) dd-norm and dx-norm {dd.norm():0.6f}, {dx.norm():0.6f}\")\n",
    "                print(f\"\\t3) dx-norm/dd-norm {dx.norm()/dd.norm():0.6f}\")\n",
    "                \n",
    "            elif sampling_test == 1:\n",
    "                reverse_score_ = diff * coeff\n",
    "                dd = - 0.5 * reverse_score_ * dt\n",
    "                print(f\"debug ] time : {t:0.3f}\")\n",
    "                print(f\"debug ] diff.norm() : {diff.norm()}\")\n",
    "                print(f\"debug ] dd.norm() : {dd.norm()}\")\n",
    "                x_tm1 = self.exponential_ode_solver(x_t, -dd, q_type=self.q_type, num_iter=inner_iteration, check_dot_every=3)\n",
    "                dx = - x_tm1 + x_t\n",
    "                print(f\"debug ] dx.norm() : {dx.norm()}\")\n",
    "                \n",
    "        x_tm1 = x_t - dx\n",
    "        return x_tm1, v1, v2, v3, v4\n",
    "\n",
    "    def reverse_score(self, x_t, t, params, x_0, x_T, verbose=True):\n",
    "        # calculate parameters\n",
    "        beta_t = params.beta(t)\n",
    "        sigma_t_square = params.sigma_square(t)\n",
    "        sigma_T_square = params.sigma_1\n",
    "\n",
    "        SNRTt = params.SNR(t)\n",
    "        sigma_t_hat_square = sigma_t_square * (1 - SNRTt)\n",
    "\n",
    "        # calc mu_hat\n",
    "        mu_hat = x_T * SNRTt + x_0 * (1 - SNRTt)\n",
    "\n",
    "        # calc difference\n",
    "        diff = mu_hat - x_t\n",
    "\n",
    "        # calc_score    \n",
    "        coeff =  1 / (sigma_t_hat_square) * beta_t\n",
    "        score = diff * coeff\n",
    "        \n",
    "        # for debug\n",
    "        if self.q_type == \"DM\":\n",
    "        # if self.q_type in [\"DM\", \"morse\"]: # debugging # calculate err corresponding the metric\n",
    "            _, d_T = self.pos_to_dist(x_T)\n",
    "            _, d_t = self.pos_to_dist(x_t)\n",
    "            _, d_0 = self.pos_to_dist(x_0)\n",
    "            _, d_mu_hat = self.pos_to_dist(mu_hat)\n",
    "            v1 = (d_mu_hat - d_t).abs().mean()\n",
    "            # v2 = (d_mu_hat - d_T).abs().mean()\n",
    "            v2 = (d_0 - d_t).abs().mean()\n",
    "            v3 = (mu_hat - x_t.numpy()).abs().mean()\n",
    "            v4 = (mu_hat - x_T.numpy()).abs().mean()\n",
    "        # elif self.q_type == \"morse\":\n",
    "        elif self.q_type in [\"morse\", \"morse+DM\", \"Cartesian\"]:\n",
    "            version = \"DMAE\"\n",
    "            # version = \"Morse-RMSD\"\n",
    "            if version == \"DMAE\":\n",
    "                d_T = torch.Tensor(pdist(x_T))\n",
    "                d_mu_hat = torch.Tensor(pdist(mu_hat))  # typo=2의 경우, 이렇게 하면 안될 듯.\n",
    "                d_t = torch.Tensor(pdist(x_t))\n",
    "                d_0 = torch.Tensor(pdist(x_0))\n",
    "                v1 = (d_mu_hat - d_t).abs().mean()\n",
    "                # v2 = (d_mu_hat - d_T).abs().mean()\n",
    "                v2 = (d_0 - d_t).abs().mean()\n",
    "                v3 = abs(mu_hat - x_t.numpy()).mean()\n",
    "                v4 = abs(mu_hat - x_T.numpy()).mean()\n",
    "            else:\n",
    "                _, d_T = self.pos_to_dist(x_T)\n",
    "                _, d_mu_hat = self.pos_to_dist(mu_hat)  # typo=2의 경우, 이렇게 하면 안될 듯.\n",
    "                _, d_t = self.pos_to_dist(x_t)\n",
    "                _, d_0 = self.pos_to_dist(x_0)\n",
    "                v1 = (d_mu_hat - d_t).norm()\n",
    "                # v2 = (d_mu_hat - d_T).abs().mean()\n",
    "                v2 = (d_0 - d_t).norm()\n",
    "                v3 = abs(mu_hat - x_t.numpy()).mean()\n",
    "                v4 = abs(mu_hat - x_T.numpy()).mean()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if verbose:\n",
    "            print(f\"{t:0.3f}\\t{v1:0.4f}\\t\\t{v2:0.4f}\\t\\t{v3:0.4f}\\t\\t{v4:0.4f}\\t\\t{torch.linalg.norm(score, dim=-1).max():0.4f}\")\n",
    "        return diff, coeff, v1, v2, v3, v4\n",
    "\n",
    "    def reverse_score2(self, x_t, t, params, x_0, x_T, verbose=True):\n",
    "        # calculate parameters\n",
    "        beta_t = params.beta(t)\n",
    "        sigma_t_square = params.sigma_square(t)\n",
    "        sigma_T_square = params.sigma_1\n",
    "\n",
    "        SNRTt = params.SNR(t)\n",
    "        sigma_t_hat_square = sigma_t_square * (1 - SNRTt)\n",
    "\n",
    "        # calc mu_hat\n",
    "        typo = 2\n",
    "        \n",
    "        if typo == 1:\n",
    "            mu_hat = x_T * SNRTt + x_0 * (1 - SNRTt)\n",
    "            _, d_mu_hat = self.pos_to_dist(mu_hat)\n",
    "        if typo == 2:\n",
    "            _, d_0 = self.pos_to_dist(x_0)\n",
    "            _, d_T = self.pos_to_dist(x_T)\n",
    "            d_mu_hat = d_T * SNRTt + d_0 * (1 - SNRTt)\n",
    "            mu_hat = x_T * SNRTt + x_0 * (1 - SNRTt)  # for debugging\n",
    "        if typo == 3:\n",
    "            mu_hat = interpolate_LST(x_0.numpy(), x_T.numpy(), SNRTt.item())\n",
    "            _, d_mu_hat = self.pos_to_dist(mu_hat)\n",
    "        \n",
    "        # calc difference\n",
    "        index, d_t = self.pos_to_dist(x_t)\n",
    "        diff_d = d_mu_hat - d_t\n",
    "        diff = diff_d\n",
    "        coeff =  1 / (sigma_t_hat_square) * beta_t\n",
    "\n",
    "        # for debugging\n",
    "        d_T = torch.Tensor(pdist(x_T))\n",
    "        d_mu_hat = torch.Tensor(pdist(mu_hat))  # typo=2의 경우, 이렇게 하면 안될 듯.\n",
    "        d_t = torch.Tensor(pdist(x_t))\n",
    "        d_0 = torch.Tensor(pdist(x_0))\n",
    "        v_loss_mae = (d_mu_hat - d_t).abs().mean()  # DMAE\n",
    "        v_acc_mae = (d_0 - d_t).abs().mean()  # DMAE\n",
    "\n",
    "        original_q_type = copy.deepcopy(self.q_type)\n",
    "        self.q_type = \"morse\"\n",
    "        _, d_T = self.pos_to_dist(x_T)\n",
    "        _, d_mu_hat = self.pos_to_dist(mu_hat)  # typo=2의 경우, 이렇게 하면 안될 듯.\n",
    "        _, d_t = self.pos_to_dist(x_t)\n",
    "        _, d_0 = self.pos_to_dist(x_0)\n",
    "        v_loss_norm = (d_mu_hat - d_t).norm()  # q-norm\n",
    "        v_acc_norm = (d_0 - d_t).norm()  # q-norm\n",
    "        self.q_type = original_q_type\n",
    "        \n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{t:0.3f}\\t{v_loss_mae:0.4f}\\t\\t{v_acc_mae:0.4f}\\t\\t{v_loss_norm:0.4f}\\t\\t{v_acc_norm:0.4f}\\t\")\n",
    "        return diff, coeff, v_loss_mae, v_acc_mae, v_loss_norm, v_acc_norm\n",
    "    \n",
    "    def exponential_ode_solver(self, x0, q_dot0, q_type=\"morse\", num_iter=100, check_dot_every=10, thresh=1e-2, max_dt=1e-1, verbose=False):\n",
    "        \n",
    "        def one_step(x, x_dot, q_type=q_type, dt=1e-2, wrapper=self, refine_xdot=False, verbose=False):\n",
    "            hess = wrapper.calc_hessian(x.reshape(-1, 3), q_type=q_type)\n",
    "            jacob = wrapper.calc_jacobian(x.reshape(-1, 3), q_type=q_type).T\n",
    "            \n",
    "            # J, J_inv = wrapper.refine_jacobian(jacob)\n",
    "            J = jacob\n",
    "            J_inv = torch.linalg.pinv(J, rtol=1e-4, atol=1e-2)\n",
    "\n",
    "            JG = J_inv.T\n",
    "            if refine_xdot:\n",
    "                x_dot = J_inv @ J @ x_dot\n",
    "                if verbose:\n",
    "                    print(f\"\\t\\t\\tdebug: x_dot norm = {x_dot.norm():0.6f}\")\n",
    "            christoffel = torch.einsum(\"mij, mk->kij\", hess, JG)\n",
    "            x_ddot = - torch.einsum(\"j,kij,i->k\", x_dot, christoffel, x_dot)\n",
    "            \n",
    "            # x_ddot and x_dot should be perpendicular \n",
    "            q_ddot = J @ x_ddot\n",
    "            q_dot = J @ x_dot\n",
    "            \n",
    "            new_x = x + x_dot * dt\n",
    "            new_x_dot = x_dot + x_ddot * dt\n",
    "            \n",
    "            # dotproduct\n",
    "            if verbose:\n",
    "                print(f\"\\t\\tdebug: <x_ddot, x_dot> = {(q_ddot * q_dot).sum()}\")\n",
    "                print(f\"\\t\\tdebug: <x_ddot, x_dot> = {((jacob.T @ jacob) @ x_dot.reshape(-1, 1) * x_ddot).sum()}\")\n",
    "                print(f\"\\t\\tdebug: x_dot size = {x_dot.norm():0.8f}, x_ddot size = {x_ddot.norm():0.8f}\")\n",
    "                print(f\"\\t\\tdebug: dx norm = {(new_x - x).norm():0.8f}, dx_dot norm = {(new_x_dot - x_dot).norm():0.8f}\")\n",
    "            return new_x, new_x_dot\n",
    "\n",
    "        \n",
    "        jacob = self.calc_jacobian(x0, q_type=q_type).T\n",
    "        # J, J_inv = self.refine_jacobian(jacob)\n",
    "        J = jacob\n",
    "        J_inv = torch.linalg.pinv(J, rtol=1e-4, atol=self.svd_tol)\n",
    "\n",
    "        # debugging\n",
    "        proj_q_dot = J @ J_inv @ q_dot0\n",
    "        if verbose >= 1:\n",
    "            print(f\"\\tdebug: proj_q_dot norm = {proj_q_dot.norm():0.4f}\")\n",
    "            print(f\"\\tdebug: proj_q_dot norm-ratio = {(proj_q_dot - q_dot0).norm()/ q_dot0.norm():0.4f}\")\n",
    "        \n",
    "        # initialization\n",
    "        x_dot0 = J_inv @ q_dot0\n",
    "        x = x0.flatten()\n",
    "        x_dot = x_dot0\n",
    "\n",
    "        total_time = x_dot.norm()\n",
    "        x_dot = x_dot / x_dot.norm()\n",
    "        \n",
    "        q = self.pos_to_dist(x.reshape(-1, 3))[1]\n",
    "        # make time grid, 0 ~ total_time.\n",
    "        # time spacing should be smaller than 1e-2\n",
    "        # thresh = 5e-2\n",
    "        # thresh = 1e-1\n",
    "        # if total_time > num_iter * thresh:\n",
    "        #     num_iter = int(total_time / thresh)\n",
    "        \n",
    "        # t = torch.linspace(0, total_time, num_iter + 1)[:-1]\n",
    "        # # t = torch.linspace(0, 1, num_iter + 1)[:-1]\n",
    "        # dt_ = t[1] - t[0]\n",
    "        # dt = dt_\n",
    "        # print(f\"\\tdebug: x_dot0.norm() = {x_dot0.norm()}\")\n",
    "        # print(f\"\\tdebug: x_dot0.norm() = {total_time.item():0.6f}\")\n",
    "        # solve the geodesic ODE iteratively\n",
    "        # for i, t_i in enumerate(t):\n",
    "        \n",
    "        dt_ = min(total_time / num_iter, thresh)\n",
    "        dt = dt_\n",
    "        if verbose >= 1:\n",
    "            print(f\"initial dt = {dt_:0.6f}, total_expected_iter = {total_time / dt_:1.0f}\")\n",
    "            \n",
    "        if verbose == 1:\n",
    "            print(\"Progress-bar\\n0%[--------------------]100%\")\n",
    "            print(\"0%[\", end=\"\")\n",
    "        current_time = 0\n",
    "        iter = 0\n",
    "        cnt = 0\n",
    "        total_dq = 0\n",
    "        while total_time > current_time:\n",
    "            # do_refine = i % check_dot_every == 0\n",
    "            do_refine = False\n",
    "            x_new, x_dot_new = one_step(x, x_dot, q_type=q_type, dt=dt, wrapper=self, refine_xdot=do_refine, verbose=verbose >= 3)\n",
    "            current_time += dt\n",
    "            \n",
    "            # calculate dq\n",
    "            q_new = self.pos_to_dist(x_new.reshape(-1, 3))[1]\n",
    "            dq = (q_new - q).norm()\n",
    "            total_dq += dq\n",
    "            q = q_new\n",
    "            if verbose >= 2:\n",
    "                if iter % 25 == 0:\n",
    "                    print(f\"\\tdebug: time = ({(current_time / total_time) * 100:0.4f}%), iter = {iter}, dt = {dt:0.6f}, dq = {dq:0.6f}\")\n",
    "            iter += 1\n",
    "            \n",
    "            x = x_new\n",
    "            x_dot = x_dot_new\n",
    "            # dt = x_dot.norm() * dt_\n",
    "            dt = min(max(dt_, 1 / x_dot.norm() * dt_), max_dt)\n",
    "            if current_time / total_time > cnt / 10 and verbose == 1:\n",
    "                print(f\"--\", end=\"\")\n",
    "                cnt += 1\n",
    "            if total_time - current_time < dt:\n",
    "                dt = total_time - current_time\n",
    "        # for i, t_i in enumerate(t):\n",
    "        #     print(f\"\\tdebug: time = {t_i:0.4f} ({i/len(t) * 100:0.2f}%)\")\n",
    "        #     # do_refine = i % check_dot_every == 0\n",
    "        #     do_refine = False\n",
    "        #     x, x_dot = one_step(x, x_dot, q_type=q_type, dt=dt, wrapper=self, refine_xdot=do_refine)\n",
    "        if verbose == 1:\n",
    "            print(\"]100%\")\n",
    "        return x.reshape(-1, 3), iter, total_dq\n",
    "    \n",
    "    \n",
    "    def svd(self, jacob, verbose=False):\n",
    "        U, S, Vh = torch.linalg.svd(jacob)\n",
    "        num_zeros = (S < self.svd_tol).sum()\n",
    "        dim = len(S) - num_zeros\n",
    "        S = S[:dim]\n",
    "        U = U[:, :dim]\n",
    "        Vh = Vh[:dim, :]\n",
    "        if verbose:\n",
    "            print(f\"\\t\\t\\tdebug: dim = {dim}, num_zeros = {num_zeros}, singular values = {S[-1].item():0.6f} ~ {S[0].item():0.6f}\")\n",
    "        return U, S, Vh\n",
    "\n",
    "    def refine_jacobian(self, jacob):\n",
    "        # find non-zero singular values\n",
    "        U, S, Vh = self.svd(jacob)\n",
    "        J = U @ torch.diag(S) @ Vh\n",
    "        J_inv = Vh.T @ torch.diag(1 / S) @ U.T\n",
    "        return J, J_inv\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $d_e$, $q_{ij}$.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 6, 7, 8\n",
    "atomic_radius = torch.zeros(100)\n",
    "atomic_radius[1] = ATOMIC_RADIUS[\"H\"]\n",
    "atomic_radius[6] = ATOMIC_RADIUS[\"C\"]\n",
    "atomic_radius[7] = ATOMIC_RADIUS[\"N\"]\n",
    "atomic_radius[8] = ATOMIC_RADIUS[\"O\"]\n",
    "atomic_radius = torch.Tensor(atomic_radius)\n",
    "\n",
    "def compute_de(edge_index, atom_type, atomic_radius):\n",
    "    \"\"\"\n",
    "    Compute equilibrium distance between two atom.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        atom_type (torch.Tensor): atom type tensor (N, )\n",
    "        atomic_radius (torch.Tensor): pre-defined atomic radius tensor (100, )\n",
    "    Returns:\n",
    "        d_e_ij (torch.Tensor): equilibrium distance tensor (E, )\n",
    "    \"\"\"\n",
    "    d_e_ij = atomic_radius[atom_type[edge_index]].sum(0)\n",
    "    return d_e_ij\n",
    "\n",
    "def compute_d(edge_index, pos):\n",
    "    \"\"\"\n",
    "    Compute distance between two atom.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        d_ij (torch.Tensor): distance tensor (E, )\n",
    "    \"\"\"\n",
    "    i, j = edge_index\n",
    "    return (pos[i] - pos[j]).norm(dim=1)\n",
    "\n",
    "def compute_q(edge_index, atom_type, pos, alpha=1.6, beta=2.3):\n",
    "    \"\"\"\n",
    "    Compute 'morse' like coordinate.\n",
    "    q_ij = exp(-alpha * (d_ij - d_e_ij) / d_e_ij) + beta * (d_e_ij / d_ij)\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        atom_type (torch.Tensor): atom type tensor (N, )\n",
    "        pos (torch.Tensor): position tensor (N, 3) \n",
    "    Returns:\n",
    "        q_ij (torch.Tensor): q tensor (E, )\n",
    "    \"\"\"\n",
    "    d_ij = compute_d(edge_index, pos)\n",
    "    d_e_ij = compute_de(edge_index, atom_type, atomic_radius)\n",
    "    q_ij = torch.exp(-alpha * (d_ij - d_e_ij) / d_e_ij) + beta * (d_e_ij / d_ij)\n",
    "    return q_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_repeat(x, n):\n",
    "    return x.unsqueeze(-1).expand(-1, n).flatten()\n",
    "\n",
    "def my_stack(x):\n",
    "    return torch.stack([3 * x, 3 * x + 1, 3 * x + 2]).T.flatten()\n",
    "\n",
    "def sparse_calc_jacobian_d(edge_index, pos):\n",
    "    \"\"\"\n",
    "    Compute jacobian matrix of d_ij.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        atom_type (torch.Tensor): atom type tensor (N, )\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        jacobian (torch.Tensor, ): jacobian matrix tensor, expected size (E, 3N)\n",
    "    \"\"\"\n",
    "    N = pos.size(0)\n",
    "    E = edge_index.size(1)\n",
    "    \n",
    "    i, j = edge_index\n",
    "    k = torch.arange(i.size(0))\n",
    "\n",
    "    d_ij = compute_d(edge_index, pos)\n",
    "    dd_dx = (pos[i] - pos[j]) / d_ij[:, None]\n",
    "    # dd_ij/dx_i = (x_i - x_j) / d_ij\n",
    "    dd_dx = dd_dx.flatten()\n",
    "    \n",
    "    k = k.unsqueeze(-1).expand(E, 3).flatten()\n",
    "    i = torch.stack([3 * i, 3 * i + 1, 3 * i + 2]).T.reshape(-1)\n",
    "    j = torch.stack([3 * j, 3 * j + 1, 3 * j + 2]).T.reshape(-1)\n",
    "    \n",
    "    jacobian = torch.sparse_coo_tensor(\n",
    "        torch.stack([k, i]), dd_dx, (E, 3 * N)\n",
    "    )\n",
    "    jacobian += torch.sparse_coo_tensor(\n",
    "        torch.stack([k, j]), -dd_dx, (E, 3 * N)\n",
    "    )\n",
    "    return jacobian\n",
    "\n",
    "def sparse_calc_jacobian_q(edge_index, atom_type, pos, alpha=1.6, beta=2.3):\n",
    "    \"\"\"\n",
    "    Compute jacobian matrix of q_ij.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E), we consider directed graph\n",
    "        atom_type (torch.Tensor): atom type tensor (N, )\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        jacobian (torch.coo-Tensor, ): jacobian matrix sparse-coo tensor, expected size (E, 3N)\n",
    "    \"\"\"\n",
    "    N = pos.size(0)\n",
    "    E = edge_index.size(1)\n",
    "    # dq/dx = dq/dd * dd/dx\n",
    "    \n",
    "    i, j = edge_index\n",
    "    k = torch.arange(i.size(0))\n",
    "\n",
    "    d_ij = compute_d(edge_index, pos)\n",
    "    d_e_ij = compute_de(edge_index, atom_type, atomic_radius)\n",
    "    dd_dx = (pos[i] - pos[j]) / d_ij[:, None]\n",
    "    # dd_ij/dx_i = (x_i - x_j) / d_ij\n",
    "    # dq_ij/dd_ij = - alpha / d_e_ij * exp(- alpha / d_e_ij * (d_ij - d_e_ij)) - beta * d_e_ij / d_ij ** 2\n",
    "    \n",
    "    dq_dd = - alpha / d_e_ij * torch.exp(- alpha / d_e_ij * (d_ij - d_e_ij)) - beta * d_e_ij / d_ij ** 2\n",
    "    \n",
    "    dq_dx = dq_dd.unsqueeze(-1) * dd_dx # (E, 3)\n",
    "    \n",
    "    k = k.unsqueeze(-1).expand(E, 3).flatten()\n",
    "    i = torch.stack([3 * i, 3 * i + 1, 3 * i + 2]).T.reshape(-1)\n",
    "    j = torch.stack([3 * j, 3 * j + 1, 3 * j + 2]).T.reshape(-1)\n",
    "\n",
    "    jacobian = torch.sparse_coo_tensor(\n",
    "        torch.stack([k, i]), dq_dx.flatten(), (E, 3 * N)\n",
    "    )\n",
    "    jacobian += torch.sparse_coo_tensor(\n",
    "        torch.stack([k, j]), -dq_dx.flatten(), (E, 3 * N)\n",
    "    )\n",
    "    return jacobian\n",
    "\n",
    "def calc_jacobian_d(edge_index, pos):\n",
    "    \"\"\"\n",
    "    Compute jacobian matrix of d_ij.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        jacobian (torch.Tensor, ): jacobian matrix tensor, expected size (E, 3N)\n",
    "    \"\"\"\n",
    "    jacobian = sparse_calc_jacobian_d(edge_index, pos).to_dense()\n",
    "    return jacobian\n",
    "\n",
    "def calc_jacobian_q(edge_index, atom_type, pos, alpha=1.6, beta=2.3):\n",
    "    \"\"\"\n",
    "    Compute jacobian matrix of q_ij.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        atom_type (torch.Tensor): atom type tensor (N, )\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        jacobian (torch.Tensor, ): jacobian matrix tensor, expected size (E, 3N)\n",
    "    \"\"\"\n",
    "    jacobian = sparse_calc_jacobian_q(edge_index, atom_type, pos, alpha=1.6, beta=2.3).to_dense()\n",
    "    return jacobian\n",
    "    \n",
    "def calc_hessian_d(edge_index, pos):\n",
    "    \"\"\"\n",
    "    Compute hessian matrix of d_ij.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        hessian (torch.Tensor, ): hessian matrix tensor, expected size (E, 3N, 3N)\n",
    "    \"\"\"\n",
    "    N = pos.size(0)\n",
    "    E = edge_index.size(1)\n",
    "    d_ij = compute_d(edge_index, pos)\n",
    "    i, j = edge_index\n",
    "    k = torch.arange(i.size(0))\n",
    "    \n",
    "    # first calculate hessian of d_ij, which is shape of (E, 3, 3) \n",
    "    d_pos = pos[i] - pos[j] # (E, 3)\n",
    "    hess_d_ij = d_pos.reshape(-1, 1, 3) * d_pos.reshape(-1, 3, 1) / (d_ij.reshape(-1, 1, 1) ** 3)\n",
    "    eye = torch.eye(3).reshape(1, 3, 3).to(d_ij.device)\n",
    "    hess_d_ij -= eye / d_ij.reshape(-1, 1, 1)\n",
    "    \n",
    "    hess_d_ii = - hess_d_ij\n",
    "    hess_d_jj = - hess_d_ij\n",
    "    hess_d_ji = hess_d_ij\n",
    "    \n",
    "    # hessian of d is shape of (E, 3N, 3N)\n",
    "    # Firstly, make it sparse tensor\n",
    "    k = my_repeat(k, 9)\n",
    "    col_i = my_stack(my_repeat(i, 3))\n",
    "    row_i = my_repeat(my_stack(i), 3)\n",
    "    col_j = my_stack(my_repeat(j, 3))\n",
    "    row_j = my_repeat(my_stack(j), 3)\n",
    "    hess = torch.sparse_coo_tensor(\n",
    "        torch.stack([k, row_i, col_i]), hess_d_ii.flatten(), (E, 3 * N, 3 * N)\n",
    "    )\n",
    "    hess += torch.sparse_coo_tensor(\n",
    "        torch.stack([k, row_j, col_j]), hess_d_jj.flatten(), (E, 3 * N, 3 * N)\n",
    "    )\n",
    "    hess += torch.sparse_coo_tensor(\n",
    "        torch.stack([k, row_i, col_j]), hess_d_ij.flatten(), (E, 3 * N, 3 * N)\n",
    "    )\n",
    "    hess += torch.sparse_coo_tensor(\n",
    "        torch.stack([k, row_j, col_i]), hess_d_ji.flatten(), (E, 3 * N, 3 * N)\n",
    "    )\n",
    "    \n",
    "    hessian = hess.to_dense()\n",
    "    return hessian\n",
    "\n",
    "def calc_hessian_q(edge_index, atom_type, pos, alpha=1.6, beta=2.3):\n",
    "    \"\"\"\n",
    "    Compute hessian matrix of q_ij.\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): edge index tensor (2, E)\n",
    "        atom_type (torch.Tensor): atom type tensor (N, )\n",
    "        pos (torch.Tensor): position tensor (N, 3)\n",
    "    Returns:\n",
    "        hessian (torch.Tensor, ): hessian matrix tensor, expected size (E, 3N, 3N)\n",
    "    \"\"\"\n",
    "\n",
    "    hessian_d = calc_hessian_d(edge_index, pos)\n",
    "    jacobian_d = calc_jacobian_d(edge_index, pos)\n",
    "    # d^2q/dadb = d^2d/dadb * K1(d) + dd/da * dd/db * K2(d)\n",
    "    # K2(d) = d^2q/dd^2 \n",
    "    # = (alpha / d_e_ij) ** 2 * exp(-alpha * (d_ij - d_e_ij) / d_e_ij) + 2 * beta * d_e_ij / d_ij ** 3\n",
    "    # K1(d) = dq/dd \n",
    "    # = -alpha * exp(-alpha * (d_ij - d_e_ij) / d_e_ij) / d_e_ij - beta * d_e_ij / d_ij ** 2\n",
    "    \n",
    "    d_ij = compute_d(edge_index, pos)\n",
    "    d_e_ij = compute_de(edge_index, atom_type, atomic_radius)\n",
    "    K1 = - (alpha / d_e_ij) * torch.exp(-alpha * (d_ij - d_e_ij) / d_e_ij) - beta * d_e_ij / d_ij ** 2\n",
    "    K2 = (alpha / d_e_ij) ** 2 * torch.exp(-alpha * (d_ij - d_e_ij) / d_e_ij) + 2 * beta * d_e_ij / d_ij ** 3\n",
    "    \n",
    "    hessian_q = K1.reshape(-1, 1, 1) * hessian_d + K2.reshape(-1, 1, 1) * jacobian_d.unsqueeze(1) * jacobian_d.unsqueeze(2)\n",
    "    return hessian_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50050/1310869182.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  edge_index = torch.Tensor(index).long()\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "a_data = datamodule.train_dataset[idx]\n",
    "atom_type = a_data.x\n",
    "# edge_index = a_data.edge_index\n",
    "# get upper triangular index of N x N matrix\n",
    "index = np.triu_indices(len(atom_type), 1)\n",
    "edge_index = torch.Tensor(index).long()\n",
    "\n",
    "pos_1 = a_data.pos_1\n",
    "pos_2 = a_data.pos_2\n",
    "atoms_0 = ase.Atoms(symbols=atom_type, positions=pos_1)\n",
    "atoms_T = ase.Atoms(symbols=atom_type, positions=pos_2)\n",
    "wrapper = Wrapper(atoms_0, atoms_T, q_type=\"morse\", alpha=1.6, beta=2.3, gamma=0.0, using_jacobian=True, svd_tol=1e-4)\n",
    "\n",
    "pos = pos_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check every differentitation function is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_e is same? : True\n",
      "d is same? : True\n",
      "q is same? : True\n",
      "------------------------------------\n",
      "d-jacobian is same? : True\n",
      "d-jacobian norm diff = 4.082286002664526e-07\n",
      "q-jacobian is same? : True\n",
      "q-jacobian norm diff = 1.625652109717903e-06\n",
      "------------------------------------\n",
      "d-hessian is same? : True\n",
      "d-hessian norm diff = 7.666445624956989e-07\n",
      "q-hessian is same? : True\n",
      "q-hessian norm diff = 7.569197015296669e-06\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=8, sci_mode=False)\n",
    "\n",
    "d_e_old = torch.Tensor(wrapper.get_re(atoms_0))\n",
    "d_e_new = compute_de(edge_index, atom_type, atomic_radius)\n",
    "print(f\"d_e is same? : {(abs(d_e_old - d_e_new) < 1e-6).all()}\")\n",
    "\n",
    "d_old = torch.Tensor(pdist(pos_1))\n",
    "d_new = compute_d(edge_index, pos_1)\n",
    "print(f\"d is same? : {(abs(d_old - d_new) < 1e-6).all()}\")\n",
    "\n",
    "q_old = wrapper.pos_to_dist(pos_1)[1]\n",
    "q_new = compute_q(edge_index, atom_type, pos_1)\n",
    "print(f\"q is same? : {(abs(q_old - q_new) < 1e-6).all()}\")\n",
    "print(\"------------------------------------\")\n",
    "jacob_old = wrapper.calc_jacobian(pos_1, q_type=\"DM\").T\n",
    "jacob_new = calc_jacobian_d(edge_index, pos_1)\n",
    "print(f\"d-jacobian is same? : {(abs(jacob_old - jacob_new) < 1e-6).all()}\")\n",
    "print(f\"d-jacobian norm diff = {(jacob_old - jacob_new).norm()}\")\n",
    "\n",
    "jacob_old = wrapper.calc_jacobian(pos_1, q_type=\"morse\").T\n",
    "jacob_new = calc_jacobian_q(edge_index, atom_type, pos_1, alpha=1.6, beta=2.3)\n",
    "print(f\"q-jacobian is same? : {(abs(jacob_old - jacob_new) < 1e-6).all()}\")\n",
    "print(f\"q-jacobian norm diff = {(jacob_old - jacob_new).norm()}\")\n",
    "print(\"------------------------------------\")\n",
    "hess_old = wrapper.calc_hessian(pos_1, q_type=\"DM\")\n",
    "hess_new = calc_hessian_d(edge_index, pos_1)\n",
    "print(f\"d-hessian is same? : {(abs(hess_old - hess_new) < 1e-6).all()}\")\n",
    "print(f\"d-hessian norm diff = {(hess_old - hess_new).norm()}\")\n",
    "\n",
    "hess_old = wrapper.calc_hessian(pos_1, q_type=\"morse\")\n",
    "hess_new = calc_hessian_q(edge_index, atom_type, pos_1, alpha=1.6, beta=2.3)\n",
    "print(f\"q-hessian is same? : {(abs(hess_old - hess_new) < 1e-5).all()}\")\n",
    "print(f\"q-hessian norm diff = {(hess_old - hess_new).norm()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
