{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import ase.io\n",
    "import ase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/share/DATA/TSDiff/utils\")\n",
    "import alignXYZ\n",
    "from checkConnectivity import MolGraph, AseAtoms2MolGraph, SanitizationError, CheckConnectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRC computation log directories\n",
    "\n",
    "seed : 0 ~ 7\n",
    "\n",
    "sample_idx : 0 ~ 1196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = glob.glob(\"/home/share/DATA/TSDiff/dft_results/IRC_results/ensemble_sample_all/ensemble_irc_total/seed0/sample_*\")\n",
    "idx_list = [int(osp.basename(dir).split(\"_\")[1]) for dir in directories]\n",
    "idx_list.sort()\n",
    "idx_list == list(range(len(idx_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist\n",
    "\n",
    "For each log file, we need to check the things\n",
    "\n",
    "1. Has the TS converged correctly? (1st-order saddle point?)\n",
    "\n",
    "2. Has the IRC computation has converged?\n",
    "\n",
    "3. The forward and backward equilibrium points are consistent with the corresponding reaction graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS optimization convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [14:20<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def check_tsopt_convergence(log_file):\n",
    "    if not osp.isfile(log_file):\n",
    "        return False\n",
    "    \n",
    "    with open(log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    # check if the optimization is converged\n",
    "    conv = False\n",
    "    for line in lines:\n",
    "        if \"OPTIMIZATION HAS CONVERGED\" in line:\n",
    "            conv = True\n",
    "    \n",
    "    if not conv:\n",
    "        return False\n",
    "    \n",
    "    # check the number of imaginary frequency\n",
    "    freq_lines = \"\".join(lines).split(\"VIBRATIONAL FREQUENCIES\")[-1]\n",
    "    imag_cnt = 0\n",
    "    for line in freq_lines.split(\"\\n\"):\n",
    "        if \"***imaginary mode***\" in line:\n",
    "            imag_cnt += 1\n",
    "    conv = (imag_cnt == 1) and conv\n",
    "    return conv\n",
    "\n",
    "tsopt_convergence_result = []\n",
    "for IDX in tqdm.tqdm(range(1197)):\n",
    "    data_ = {\"sample_index\": IDX}\n",
    "    for SEED in range(8):\n",
    "        tsopt_log = f\"/home/share/DATA/TSDiff/dft_results/tsopt_result/ensemble_sample_all/seed{SEED}_even/sample_{IDX}/log\"\n",
    "        check = check_tsopt_convergence(tsopt_log)\n",
    "        data_[SEED] = check\n",
    "    tsopt_convergence_result.append(data_)\n",
    "tsopt_convergence_result = pd.DataFrame(tsopt_convergence_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRC computation convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [02:24<00:00,  8.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def check_IRC_convergence(log_file):\n",
    "    if not osp.isfile(log_file):\n",
    "        return False\n",
    "    \n",
    "    with open(log_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    cnt = 0\n",
    "    for line in lines:\n",
    "        if \"THE IRC HAS CONVERGED\" in line:\n",
    "            cnt += 1\n",
    "\n",
    "    if cnt == 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "irc_convergence_result = []\n",
    "for IDX in tqdm.tqdm(range(1197)):\n",
    "    data_ = {\"sample_index\": IDX}\n",
    "    for SEED in range(8):\n",
    "        irc_log = f\"/home/share/DATA/TSDiff/dft_results/IRC_results/ensemble_sample_all/ensemble_irc_total/seed{SEED}/sample_{IDX}/log\"\n",
    "        check = check_IRC_convergence(irc_log)\n",
    "        data_[SEED] = check\n",
    "    irc_convergence_result.append(data_)\n",
    "irc_convergence_result = pd.DataFrame(irc_convergence_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency between IRC end-points and reaction graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [02:44<00:00,  7.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def check_IRC_consistency(xyz_file, r_atoms, p_atoms):\n",
    "    if not osp.isfile(xyz_file):\n",
    "        return False\n",
    "    \n",
    "    return CheckConnectivity(xyz_file, r_atoms, p_atoms)\n",
    "\n",
    "# check the connectivity of the R, P and end points\n",
    "refRxyz = \"/home/share/DATA/TSDiff/data/TS/wb97xd3/random_split_42/sorted_testset/wb97xd3_r_test_nodollar_even.xyz\"\n",
    "refPxyz = \"/home/share/DATA/TSDiff/data/TS/wb97xd3/random_split_42/sorted_testset/wb97xd3_p_test_nodollar_even.xyz\"\n",
    "R_atoms = list(ase.io.iread(refRxyz))\n",
    "P_atoms = list(ase.io.iread(refPxyz))\n",
    "\n",
    "irc_consistency_result = []\n",
    "for IDX in tqdm.tqdm(range(1197)):\n",
    "    data_ = {\"sample_index\": IDX}\n",
    "    for SEED in range(8):\n",
    "        irc_xyz_file = f\"/home/share/DATA/TSDiff/dft_results/IRC_results/ensemble_sample_all/ensemble_irc_total/seed{SEED}/sample_{IDX}/input_IRC_Full_trj.xyz\"\n",
    "        check = check_IRC_consistency(irc_xyz_file, R_atoms[IDX], P_atoms[IDX])\n",
    "        data_[SEED] = check\n",
    "    irc_consistency_result.append(data_)\n",
    "irc_consistency_result = pd.DataFrame(irc_consistency_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = tsopt_convergence_result[[0, 1, 2, 3, 4, 5, 6, 7]].to_numpy()\n",
    "cond2 = irc_convergence_result[[0, 1, 2, 3, 4, 5, 6, 7]].to_numpy()\n",
    "cond3 = irc_consistency_result[[0, 1, 2, 3, 4, 5, 6, 7]].to_numpy()\n",
    "\n",
    "cond = np.logical_and(np.logical_and(cond1, cond2), cond3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1191</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1193</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1194</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1195</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1196</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx  seed\n",
       "0        0  (0,)\n",
       "1        1  (0,)\n",
       "2        2  (0,)\n",
       "3        3  (0,)\n",
       "4        4  (0,)\n",
       "...    ...   ...\n",
       "1017  1191  (0,)\n",
       "1018  1193  (0,)\n",
       "1019  1194  (0,)\n",
       "1020  1195  (0,)\n",
       "1021  1196  (0,)\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_samples = []\n",
    "for IDX in range(1197):\n",
    "    if not np.any(cond[IDX]):\n",
    "        continue\n",
    "    _ = {'idx': IDX, 'seed': tuple(np.where(cond[IDX])[0])}\n",
    "    selected_samples.append(_)\n",
    "selected_samples = pd.DataFrame(selected_samples)\n",
    "selected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1022/1022 [01:09<00:00, 14.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def distinguish_conformers(smarts, xyz_files, log_files):\n",
    "    matches = alignXYZ.get_substruct_matches(smarts)\n",
    "    positions = []\n",
    "    for xyz in xyz_files:\n",
    "        atoms = ase.io.read(xyz)\n",
    "        positions.append(atoms.positions)\n",
    "\n",
    "    distance_matrix = np.zeros((len(positions), len(positions)))\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(len(positions)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            match_perm, origin, dist = alignXYZ.get_min_dmae_match(matches, positions[i], positions[j])\n",
    "            distance_matrix[i, j] = dist\n",
    "\n",
    "    # check energies from log_files\n",
    "    hartree2kcalmol = 627.509\n",
    "    energies = []\n",
    "    for log in log_files:\n",
    "        with open(log, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[::-1]:\n",
    "                if \"Total thermal energy\" in line:\n",
    "                    energy = float(line.split()[-2]) * hartree2kcalmol\n",
    "                    energies.append(energy)\n",
    "                    break\n",
    "\n",
    "    energy_diff_matrix = np.zeros((len(energies), len(energies)))\n",
    "    for i in range(len(energies)):\n",
    "        for j in range(len(energies)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            energy_diff = abs(energies[i] - energies[j])\n",
    "            energy_diff_matrix[i, j] = energy_diff\n",
    "\n",
    "    edge = np.logical_and(distance_matrix < 0.01, energy_diff_matrix < 0.1)\n",
    "    for i in range(len(edge)):\n",
    "        edge[i, i] = False\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for i in range(len(edge)):\n",
    "        G.add_node(i)\n",
    "    for i in range(len(edge)):\n",
    "        for j in range(len(edge)):\n",
    "            if edge[i, j]:\n",
    "                G.add_edge(i, j)\n",
    "    # find connected components\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    # pos = nx.spring_layout(G)\n",
    "    # nx.draw(G, pos, with_labels=True)\n",
    "    # plt.show()\n",
    "    return tuple([list(connected)[0] for connected in connected_components])\n",
    "\n",
    "infos = pd.read_csv('/home/share/DATA/TSDiff/data/TS/wb97xd3/random_split_42/sorted_testset/wb97xd3_testset_info.csv')\n",
    "pruned_samples = []\n",
    "for IDX in tqdm.tqdm(selected_samples['idx']):\n",
    "    seeds = selected_samples[selected_samples['idx'] == IDX]['seed'].values[0]\n",
    "    if len(seeds) == 1:\n",
    "        _ = {'idx': IDX, 'seed': seeds, 'grambow_index': infos.iloc[2 * IDX]['log_index'], \"smarts\": infos.AAM[2 * IDX]}\n",
    "    else:\n",
    "        xyz_files = []\n",
    "        for seed in seeds:\n",
    "            xyz = f\"/home/share/DATA/TSDiff/dft_results/tsopt_result/ensemble_sample_all/seed{seed}_even/sample_{IDX}/input.xyz\"\n",
    "            xyz_files.append(xyz)\n",
    "        log_files = []\n",
    "        for seed in seeds:\n",
    "            log = f\"/home/share/DATA/TSDiff/dft_results/tsopt_result/ensemble_sample_all/seed{seed}_even/sample_{IDX}/log\"\n",
    "            log_files.append(log)\n",
    "        smarts = infos.AAM[::2].to_list()[IDX]\n",
    "        \n",
    "        seeds = distinguish_conformers(smarts, xyz_files, log_files)\n",
    "        _ = {'idx': IDX, 'seed': seeds, 'grambow_index': infos.iloc[2 * IDX]['log_index'], \"smarts\": infos.AAM[2 * IDX]}\n",
    "    pruned_samples.append(_)\n",
    "pruned_samples = pd.DataFrame(pruned_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/share/DATA/NeuralOpt/SQM_data/TSDifftoDFT\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "cnt = 0\n",
    "test_dataset_index = []\n",
    "for sample in pruned_samples.iloc:\n",
    "    sample.idx, sample.seed, sample.grambow_index, sample.smarts\n",
    "    IDX = sample.idx\n",
    "    for SEED in sample.seed:\n",
    "        traj = f\"/home/share/DATA/TSDiff/dft_results/tsopt_result/ensemble_sample_all/seed{SEED}_even/sample_{IDX}/input_trj.xyz\"\n",
    "        atoms = list(ase.io.iread(traj))\n",
    "        opt_atoms = atoms[-1]\n",
    "        init_atoms = atoms[0]\n",
    "\n",
    "        opt_log = f\"/home/share/DATA/TSDiff/dft_results/tsopt_result/ensemble_sample_all/seed{SEED}_even/sample_{IDX}/input.opt\"\n",
    "        with open(opt_log, \"r\") as f:\n",
    "            lines = f.read()\n",
    "        for sec in lines.split('$'):\n",
    "            if \"energies\" in sec:\n",
    "                energies = sec.split(\"\\n\")[2:-2]\n",
    "        opt_energy = float(energies[-1])\n",
    "        init_energy = float(energies[0])\n",
    "        \n",
    "        comment = f'idx={cnt} smarts=\"{sample.smarts}\" sample_index={IDX} seed={SEED} grambow_index={sample.grambow_index} init_energy={init_energy} opt_energy={opt_energy}'\n",
    "        save_xyz = osp.join(save_dir, f\"idx{cnt}.xyz\")\n",
    "        ase.io.write(save_xyz, opt_atoms, comment=comment)\n",
    "        ase.io.write(save_xyz, init_atoms, comment=comment, append=True)\n",
    "        test_dataset_index.append(cnt)\n",
    "        cnt += 1\n",
    "        \n",
    "grambow_index_dict = \"/home/share/DATA/TSDiff/data/TS/wb97xd3/random_split_42/index_list.pkl\"\n",
    "grambow_index_dict = pd.read_pickle(grambow_index_dict)\n",
    "train_index = grambow_index_dict['train_index']\n",
    "valid_index = grambow_index_dict['valid_index']\n",
    "\n",
    "dataset = list(ase.io.iread(\"/home/share/DATA/TSDiff/data/TS/wb97xd3/raw_data/wb97xd_nodollar_ts.xyz\"))\n",
    "dataset_info = pd.read_csv(\"/home/share/DATA/TSDiff/data/TS/wb97xd3/raw_data/wb97xd_fwd_rev_chemprop.csv\")\n",
    "\n",
    "train_dataset_index = []\n",
    "for grambow_index in train_index:\n",
    "    smarts = dataset_info.AAM[grambow_index]\n",
    "    comment = f'idx={cnt} smarts=\"{smarts}\" grambow_index={grambow_index}'\n",
    "    atoms = dataset[grambow_index]\n",
    "    save_xyz = osp.join(save_dir, f\"idx{cnt}.xyz\")\n",
    "    ase.io.write(save_xyz, atoms, comment=comment)\n",
    "   \n",
    "    train_dataset_index.append(cnt)\n",
    "    cnt += 1\n",
    "\n",
    "valid_dataset_index = []\n",
    "for grmabow_index in valid_index:\n",
    "    smarts = dataset_info.AAM[grambow_index]\n",
    "    save_xyz = osp.join(save_dir, f\"idx{cnt}.xyz\")\n",
    "    comment = f'idx={cnt} smarts=\"{smarts}\" grambow_index={grambow_index}'\n",
    "    atoms = dataset[grambow_index]\n",
    "    ase.io.write(save_xyz, atoms, comment=comment)\n",
    "    \n",
    "    valid_dataset_index.append(cnt)\n",
    "    cnt += 1\n",
    "\n",
    "dataset_index_dict = {\"train_index\": train_dataset_index, \"valid_index\": valid_dataset_index, \"test_index\": test_dataset_index}\n",
    "save_pkl = osp.join(save_dir, \"data_split.pkl\")\n",
    "pd.to_pickle(dataset_index_dict, save_pkl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
